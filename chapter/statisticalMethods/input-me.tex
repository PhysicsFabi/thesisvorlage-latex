\def\currentRootFolder{chapter/statisticalMethods}
\def\currentFigureFolder{\currentRootFolder/fig}
\input{\currentRootFolder/symbols.tex}
\input{\currentRootFolder/glossaries.tex}
\chapter{Statistical Methods and Neutrino Mass Inference at KATRIN}
\label{sec:statMethods}
The neutrino mass $m_\nu$ alongside with an uncertainty will be retrieved by comparing the output of the KATRIN measurement with theoretical predictions. This process is called parameter inference. There exist different statistical approaches. They differ in practicality as well as interpretation. The so-called KaFit software framework implements several corresponding tools tailored to the KATRIN experiment. It is interfaced to \gls{ssc} (section \ref{sec:intSpecModel}). A description of KaFit can e.g. be found in \cite{Kleesiek2014}. This chapter outlines a selection of statistical approaches following mainly the statistics chapter of the Review of Particle Physics \cite{ReviewOfParticlePhysics}. Additionally, within this thesis the implementations in KaFit were extended, which will also be described.

\section{The Maximum Likelihood Estimator}
The likelihood is the probability of a measurement outcome given a hypothesis. A hypothesis depending on a parameter vector $\paramVec$ is called a composite hypothesis. A measurement outcome can be quantified by a vector of observed values $\dataVec$. The probability $P$ of $\dataVec$ given a hypothesis in dependence of $\paramVec$ is called the likelihood function
\begin{equation}
	L(\paramVec) = P\giventhat{\dataVec}{\paramVec}
	\fullstop
\end{equation}
If $p$ denotes the probability for one observed value $x_i$ in $\dataVec$, then the likelihood function can be written as a product
\begin{equation}
	L(\paramVec) = \prod_{i} p\giventhat{x_i}{\paramVec}
	\fullstop
\end{equation}
The parameter vector $\hat{\paramVec}$ that maximizes the likelihood function is called the \gls{mle} for the true values of $\paramVec$.

\section{The KATRIN Likelihood}
The \gls{mle}-method can be applied to a KATRIN measurement as follows: The data vector is given by a set of $n$ electron counts $\left\{\Nobsi\right\}$ measured at different retarding potentials $qU_i$. The hypothesis is that these counts follow a Poisson distribution with predicted expected electron counts $\left\{\Ntheoi\right\}$ as e.g. in \eqref{eq:countsSCCFinal}. For sufficiently high counts the Poisson distribution can be approximated by a Gaussian distribution $\mathcal{N}(x,\mu, \sigma)$ with mean $\mu=\Ntheoi(\paramVec)$ and standard deviation $\sigma=\sqrt{\Nobsi}$. The likelihood function then reads
\begin{equation}
	\label{eq:KATRINlikelihood}
	L(\paramVec) = \prod_{i}^{n} \mathcal{N}\left(\Nobsi,\mu=\Ntheoi(\paramVec), \sigma=\sqrt{\Nobsi}\right)
	\fullstop
\end{equation}
Commonly, instead of maximizing the likelihood function, its negative logarithm is minimized and a factor 2 is introduced
\begin{equation}
	\label{eq:katrinChi2}
	-2\ln L(\paramVec) = \chi^2(\paramVec) = \sum_i^n
		\left( 
			\frac{\Nobsi-\Ntheoi(\paramVec)}{\sqrt{\Nobsi}}
		\right)^2
		 + \mathrm{constants}
		\fullstop
\end{equation}
Under the made assumptions this expression is a sum of $n$ standard normal distributed random variables and hence, follows the Pearson's chi-square statistic with $n-\mathrm{dim}\paramVec$ degrees of freedom. Its minimization yields the \gls{mle} estimator $\hat{\paramVec}$ for $\paramVec$. Accordingly, the value $\chi^2(\hat{\paramVec})$ is a measure for the goodness-of-fit.

The parameter of interest in $\paramVec$ is the neutrino mass squared $m_\nu^2$. Furthermore, $\paramVec$ typically comprises the endpoint of the tritium $\upbeta$ spectrum $E_0$ \eqref{eq:endpoint}, an overall normalization factor for the counts $\As$ and the rate of the background counts $\Rbg$. For the later two see \eqref{eq:countsSCCFinal}.

\section{Confindence and Credible Intervals}
The presented maximum likelihood method provides point estimates $\hat{\paramVec}$. However, additional information can be provided by interval estimates. There are two main approaches to statistical inference, which may be called Bayesian and frequentist. They differ in their interpretation of probability which becomes especially evident by the interval estimates typically associated with the two approaches.

\subsection{Bayesian Credible Intervals}
The likelihood $L\giventhat{\dataVec}{\paramVec}$ is a probability distribution of the data $\dataVec$ given the parameters $\paramVec$. Using Bayes theorem the likelihood can be transformed into a probability density for the parameters $\paramVec$ by multiplication with a prior distribution $\pi(\paramVec)$ and normalization to 1
\begin{equation}
\label{eq:posterior}
	P\giventhat{\paramVec}{\dataVec} = 
		\frac{
			L\giventhat{\dataVec}{\paramVec}\pi(\paramVec)
		}{
			\int L\giventhat{\dataVec}{\paramVec^\prime}\pi(\paramVec^\prime) \d\paramVec^\prime
		}
	\fullstop
\end{equation}
Here, $P\giventhat{\paramVec}{\dataVec}$ is the so-called posterior distribution. So-called credible regions, in which the true parameters lie with a certain probability $\alpha$, can be extracted.  Typical values for $\alpha$ are \SI{68}{\percent} and \SI{95}{\percent}. When $\paramVec$ is one dimensional a credible region becomes a credible interval. 

\subsection{Frequentist Confidence Intervals}
In frequentist statistics, probability is interpreted as the frequency
of the outcome of a repeatable experiment. A confidence region $C(\alpha)$ of confidence level (CL) $\alpha$ for a parameter vector with true value $\paramVec_\mathrm{T}$ is the following: If an experiment were to be repeated many times and the confidence region $C(\alpha)$ were to be constructed each time according to the same recipe, it would contain the true parameter $\paramVec_\mathrm{T}$ a fraction of at least $\alpha$ times. Typical values for $\alpha$ are chosen as quantiles of the Gaussian distribution in steps of standard deviations $\sigma$. E.g. the 1- and 2-$\sigma$ levels are \SI{68}{\percent} and \SI{95}{\percent}. The Neyman construction \cite{Neyman1937} or its extension, the unified approach by Feldman and Cousins \cite{Feldman1998}, yield such confidence regions. When $\paramVec$ is one dimensional a confidence region becomes a confidence interval. 

Approximated confidence regions can be extracted from the likelihood. If the likelihood follows the form of a multivariate Gaussian distribution in $\paramVec$, then the hyper surface defined by
\begin{equation}
	\ln L(\paramVec) = 	\ln L(\hat{\paramVec}) - \frac{s^2}{2}
\end{equation}
encloses a $s$-$\sigma$ confidence region for $\paramVec$. This is the case for the KATRIN chi-square likelihood.

\section{Nuisance Parameters and the Profile Likelihood Method}

\section{The KaFit and SSC Software Frameworks}

\section{KATRIN's Sensitivity to the Electron Antineutrino Mass}
