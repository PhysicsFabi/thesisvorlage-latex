\def\currentRootFolder{chapter/statisticalMethods}
\def\currentFigureFolder{\currentRootFolder/fig}
\input{\currentRootFolder/symbols.tex}
\input{\currentRootFolder/glossaries.tex}
\chapter{Statistical Methods and Neutrino Mass Inference at KATRIN}
\label{sec:statMethods}
\todo{Unify wording: dertector counts, measured counts theoretical counts, predcited coutns, expected counts.}

The best estimator for the neutrino mass $m_\nu$ alongside with an uncertainty or an upper limit will be retrieved by comparing the output of the KATRIN measurement with theoretical predictions. This process is called parameter inference. There exist different statistical approaches. They differ in practicality as well as interpretation. This chapter reviews a selection of statistical approaches suitable in relation to the KATRIN experiment.

Section~\ref{sec:statMethodsMLE} outlines the principle of the \glsentryfull{mle}. Section~\ref{sec:statMethodsKATRINLikelihood} relates the principle of the \glsentryshort{mle} to a KATRIN measurement and neutrino mass inference. Section~\ref{sec:statMethodsUncertaintyIntervals} reviews the concept of uncertainty intervals and how confidence intervals can be extracted from the likelihood. Section~\ref{sec:statMethodsProfileLikelihood} extends the formalism to account for so-called nuisance parameters within the profile-likelihood formalism. Section~\ref{sec:statMethodsKaFitSSC} introduces the statistical software framework that was used within this thesis. And finally, section~\ref{sec:statMethodsKatrinSensitivity} deduces the neutrino mass uncertainty and explains the origin of the often quoted $\SI{200}{eV}$ (\SI{90}{\percent} C.L.) KATRIN sensitivity.

\section{Maximum Likelihood Estimation}
\label{sec:statMethodsMLE}
The likelihood is the probability of a measurement outcome given a hypothesis. A hypothesis depending on a parameter vector $\paramVec$ is called a composite hypothesis. A measurement outcome can be quantified by a vector of observed values $\dataVec$. The probability $P$ of $\dataVec$ given a hypothesis in dependence of $\paramVec$ is called the likelihood function~\cite{ReviewOfParticlePhysics}
\begin{equation}
	L(\paramVec) = P\giventhat{\dataVec}{\paramVec}
	\fullstop
\end{equation}
If $p$ denotes the probability for one observed value $x_i$ in $\dataVec$, then the likelihood function can be written as a product~\cite{ReviewOfParticlePhysics}
\begin{equation}
	L(\paramVec) = \prod_{i} p\giventhat{x_i}{\paramVec}
	\fullstop
\end{equation}
The parameter vector $\hat{\paramVec}$ that maximizes the likelihood function is called the \gls{mle} for the true values of $\paramVec$~\ref{sec:statMethodsMLE}.

\section{The Likelihood of a KATRIN measurement}
\label{sec:statMethodsKATRINLikelihood}
The \gls{mle}-method can be applied to a KATRIN measurement as follows: The data vector is given by a set of $n$ electron counts $\left\{\Nobsi\right\}$ measured at different retarding potentials $\left\{qU_i\right\}$. The hypothesis is that these counts follow a Poisson distribution with predicted expected electron counts $\left\{\Ntheoi\right\}$ as in equation \eqref{eq:intSpecModelCountsFinal}~\cite{Kleesiek2014}. For sufficiently high counts a Poisson distribution can be approximated by a Gaussian distribution $\mathcal{N}(x,\mu, \sigma)$ with mean $\mu=\Ntheoi(\paramVec)$ and standard deviation $\sigma=\sqrt{\Nobsi}$. \todo{Clearify what the right std is. SSC paper and KaFit use the theo. counts, but then the application of the ln does not yield the $\chi^2$ sum!? Also a comment right next to the Kafit code says "We are use Neyman' ChiSquare here (denominator given by measured counts variance)" But then the theo. counts are used anyway.} The likelihood function then reads
\begin{equation}
	\label{eq:KATRINlikelihood}
	L(\paramVec) = \prod_{i}^{n} \mathcal{N}\left(\Nobsi,\mu=\Ntheoi(\paramVec), \sigma=\sqrt{\Nobsi}\right)
	\fullstop
\end{equation}
Commonly, instead of maximizing the likelihood function, its negative logarithm is minimized and a factor 2 is introduced~\cite{ReviewOfParticlePhysics}. This yields
\begin{equation}
	\label{eq:statMethodsKatrinChi2}
	-2\ln L(\paramVec) = \chi^2(\paramVec) = \sum_i^n
		\left( 
			\frac{\Nobsi-\Ntheoi(\paramVec)}{\sqrt{\Nobsi}}
		\right)^2
		 + \mathrm{constants}
		\fullstop
\end{equation}
The minimization of equation~\eqref{eq:statMethodsKatrinChi2} yields the \gls{mle} estimator $\hat{\paramVec}$ for $\paramVec$.

Under the made assumptions equation~\eqref{eq:statMethodsKatrinChi2} is a sum of $n$ standard normal distributed random variables. Hence, evaluated at the \gls{mle},  $\chi^2(\hat{\paramVec})$, follows the Pearson's chi-square statistic with $n-\mathrm{dim}\paramVec$ degrees of freedom. Accordingly, the value $\chi^2(\hat{\paramVec})$ is a measure for the goodness-of-fit~\cite{ReviewOfParticlePhysics}.

In regard to a KATRIN neutrino mass measurement, the parameter of interest in $\paramVec$ is the neutrino mass squared $m_\nu^2$. Furthermore, $\paramVec$ typically comprises the endpoint of the tritium-$\upbeta$ spectrum $E_0$, an overall normalization factor for the counts $\As$ and the rate of the background counts $\Rbg$~\cite{Kleesiek2014}. For the later three see equation ~\eqref{eq:intSpecModelCountsFinal}.

\section{Uncertainty Intervals}
\label{sec:statMethodsUncertaintyIntervals}
The presented maximum likelihood method provides point estimates $\hat{\paramVec}$. However, additional information can be provided by interval estimates. There are two main approaches to statistical inference, which may be called Bayesian and frequentist~\cite{ReviewOfParticlePhysics}. They differ in their interpretation of probability, which becomes especially evident by the interval estimates associated with the two approaches: Credible and confidence intervals. Both interval types can be given with reference to quantiles of the Gaussian distribution. E.\,g.~the 1- and 2-$\sigma$ levels define \SI{68}{\percent} and \SI{95}{\percent} intervals. The following two sections explain the matter in more detail.

\subsection{Bayesian Credible Intervals}
The likelihood $L\giventhat{\dataVec}{\paramVec}$ is a probability distribution of the data $\dataVec$ given the parameters $\paramVec$. Using Bayes theorem the likelihood can be transformed into a probability density for the parameters $\paramVec$ by multiplication with a prior distribution $\pi(\paramVec)$ and normalization to one~\cite{ReviewOfParticlePhysics}
\begin{equation}
\label{eq:statMethodsPosterior}
	P\giventhat{\paramVec}{\dataVec} = 
		\frac{
			L\giventhat{\dataVec}{\paramVec}\pi(\paramVec)
		}{
			\int L\giventhat{\dataVec}{\paramVec^\prime}\pi(\paramVec^\prime) \d\paramVec^\prime
		}
	\fullstop
\end{equation}
Here, $P\giventhat{\paramVec}{\dataVec}$ is the so-called posterior distribution. So-called credible regions, in which the true parameters lie with a certain probability $\alpha$, can be extracted. As noted, typical values for $\alpha$ are \SI{68}{\percent} and \SI{95}{\percent}. When $\paramVec$ is one dimensional a credible region becomes a credible interval. 

\subsection{Frequentist Confidence Intervals}
\label{sec:statMethodsUncertaintyIntervalsConfidence}
This section first aims at defining the terms ``confidence interval'', ``coverage probability'' and ``confidence level''. On the basis of these definitions it is explained, how confidence intervals can be extracted from a likelihood in general and especially in the case of a KATRIN neutrino mass measurement.

In frequentist statistics, probability is interpreted as the frequency of the outcome of a repeatable experiment and the boundary of a so-called confidence region is given by a function of the data. There is some freedom of choice for the corresponding function. It should be noted, that in this sense, the term confidence regions is somewhat ``unqualified''~\cite{ReviewOfParticlePhysics}. But it obtains a deeper meaning in combination with a coverage probability. First, it should be noted, that the boundary of the confidence region would fluctuate if one were to repeat the experiment many times. One would obtain an ensemble of confidence regions. The so-called coverage probability $\alpha$ refers to the fraction of regions in such an ensemble that contains the true parameter values~$\paramVec_\mathrm{T}$\cite{ReviewOfParticlePhysics}. If an ensemble of confidence regions covers the true parameter values~$\paramVec_\mathrm{T}$ at least a fraction of $\alpha$ times, the confidence interval is understood to have a confidence level of $\alpha$~\cite{ReviewOfParticlePhysics}. When $\paramVec$ is one dimensional a confidence region becomes a confidence interval. 

The Neyman construction~\cite{Neyman1937} or its extension, the unified approach by Feldman and Cousins~\cite{Feldman1998}, yield such confidence regions.

An equivalent method of constructing confidence intervals is to consider a test (see hypothesis testing in~\cite{ReviewOfParticlePhysics}) of the hypothesis that the parameter values $\paramVec$ have the true values $\paramVec_\mathrm{T}$~\cite{ReviewOfParticlePhysics}. In this construction the choice of test to be used is free. One possibility is a test statistic based on the likelihood ratio between the \gls{mle} $\hat{\paramVec}$ and $\paramVec$~\cite{ReviewOfParticlePhysics}
\begin{equation}
	\label{eq:statMethodsLikelihoodRatio}
	\lambda(\paramVec) =
	\frac{L(\paramVec)}{L(\hat{\paramVec})}
	\fullstop
\end{equation}
In the case of a construction via a hypothesis test, all parameter values $\paramVec$ are excluded from the confidence interval of level $\alpha$ that are rejected by the test with a significance of $\alpha$~\cite{ReviewOfParticlePhysics}.

If the likelihood follows the form of a multivariate Gaussian distribution in $\paramVec$, then the above test statistic~\eqref{eq:statMethodsLikelihoodRatio} can be evaluated and the the hyper surface defined by
\begin{equation}
	\label{eq:statMethodsConfidenceContour}
	\ln L(\paramVec) = 	\ln L(\hat{\paramVec}) - \frac{s^2}{2}
\end{equation}
encloses a $s$-$\sigma$ confidence region for $\paramVec$~\cite{ReviewOfParticlePhysics}. (Here, $s$-$\sigma$ denotes the corresponding quantile of a Gaussian distribution.) 

The derivation of the KATRIN $\chi^2$-likelihood~\eqref{eq:statMethodsKatrinChi2} was based on the assumption of its Gaussian-like shape. In this sense, the confidence contour~\eqref{eq:statMethodsConfidenceContour} applies. 

In conclusion, in this section a recipe has been derived, that enables the extraction of confidence regions for the parameters of a KATRIN measurement, especially for the squared neutrino mass, from the KATRIN likelihood. However, in practice, finding the corresponding contours of the confidence region given by equation \ref{eq:statMethodsConfidenceContour} may not be feasible, as it is a multi-dimensional problem. In a minimal setup of a KATRIN parameter inference $\paramVec$ has at least the dimension 4 comprised by the $\upbeta$-spectrum endpoint, the background rate, the signal amplitude and the neutrino mass~\cite{Kleesiek2014}. (For the meaning of these parameters also see equation \eqref{eq:intSpecModelCountsFinal}.) When only the confidence interval for the neutrino mass is of interest, the other so-called nuisance parameters can e.\,g.~be profiled out. This procedure is reviewed section~\ref{sec:statMethodsProfileLikelihood}.

\section{Nuisance Parameters and the Profile Likelihood Method}
\label{sec:statMethodsProfileLikelihood}
Apart from the  parameters of interest $\paramVec$ (usually the squared neutrino mass), the KATRIN likelihood depends on further so-called nuisance parameters $\nuisanceParamVec$ (e.\,g. the background rate). The dimensionality may pose difficulties when deriving a confidence region for the combined parameter set. Furthermore, as indicated by the naming conventions, the dimensions of the nuisance parameters in the confidence region are not of interest. Hence, in order to derive a confidence interval with restricted dimensions, a test statistic, similar to the one in equation~\ref{eq:statMethodsLikelihoodRatio}, but that solely depends on the parameters of interest, has to be found. The following paragraph outlines, how a corresponding test statistic can be constructed using the profile likelihood method.

A corresponding derivation may start with the definition of the profile likelihood: The profile likelihood only depends on the parameters of interest $\paramVec$. Its values correspond the likelihood values evaluated at $\paramVec$ in the dimensions of the parameter of interest and maximized in the dimensions of the nuisance parameters~\cite{ReviewOfParticlePhysics}
\begin{equation}
	\profLikelihood(\paramVec) = 
	L(\paramVec, \hat{\hat{\nuisanceParamVec}}(\paramVec))
	\comma
\end{equation}
where the double-hat indicates the maximization respectively the profiling. Also, the profile likelihood ratio can be defined~\cite{ReviewOfParticlePhysics}
\begin{equation}
	\label{eq:statMethodsProfileLikelihoodRatio}
	\lambda_\mathrm{p}(\paramVec) = 
	\frac{\profLikelihood(\paramVec)}{\profLikelihood(\hat{\paramVec})}
	\fullstop
\end{equation}
According to Wilks’ theorem~\cite{wilks1938}, the distribution of $-2\ln\lambda_\mathrm{p}(\hat{\paramVec})$, where $\hat{\paramVec}$ is the \gls{mle}, approaches a $\chi^2$ distribution in the limit of a large data sample, independent of the values of the nuisance parameters $\nuisanceParamVec$~\cite{ReviewOfParticlePhysics}. Hence, the profile likelihood ratio offers a test statistic, from which a confidence interval for the parameters of interest can be derived.

In application to a KATRIN neutrino mass measurement, the introduced formalism can be summarized as follows: The profile likelihood~\eqref{eq:statMethodsProfileLikelihoodRatio} is a measure (test statistic) for whether a hypothesized squared neutrino mass has to be rejected given the KATRIN data. Furthermore, analogously to section~\ref{sec:statMethodsUncertaintyIntervalsConfidence}, this allows for the derivation of a confidence interval for the squared neutrino mass. It should be noted, however, that this method requires an extrapolation of the likelihood to nonphysical negative squared neutrino masses~\cite{Kleesiek2014}.

\section{The KaFit and SSC Software Frameworks}
\label{sec:statMethodsKaFitSSC}
With respect to neutrino mass inference at KATRIN two formalisms have been presented: the model for a KATRIN neutrino mass measurement in chapter~\ref{sec:intSpecModel} and a statistical framework in chapter~\ref{sec:statMethods}. 

The two formalisms are implemented within two modules of the so-called ``KATRIN Analysis and Simulations Package'' (KASPER)\footnote{\url{https://nuserv.uni-muenster.de:8443/katrin-git/kasper}}:
\begin{enumerate}
	\item The \textbf{\glsentryfull{ssc}} package implements the formulas for the differential and integrated spectrum calculations. Therefore, it follows the formulas given in chapter~\ref{sec:intSpecModel}. Additionally, it also includes aspects beyond the given description, such as the gas dynamics within the \gls{wgts}~\cite{Hoetzel2012, Groh2015, Kleesiek2019, Kaefer2012}.
	\item The \textbf{KaFit} package translates the $\upbeta$ spectrum calculated by \glsentryshort{ssc} into expected detector counts. Furthermore, KaFit implements several statistic tools tailored to the KATRIN experiment. One of which is the extraction of confidence intervals according to the profile likelihood method section~\ref{sec:statMethodsUncertaintyIntervalsConfidence}. The actual minimization and profiling are done by the interfaced MINUIT2 and MINOS package from the ROOT\footnote{\url{http://root.cern.ch/}}~\cite{ANTCHEVA2009} analysis framework~\cite{Kleesiek2014}.
\end{enumerate}

Both packages were extended to allow for the analysis done within the scope of this thesis as will be explained in chapters~\ref{sec:energyDepScat} and~\ref{sec:katrinEloss}.

\section{KATRIN's Sensitivity to the Electron Antineutrino Mass}
\label{sec:statMethodsKatrinSensitivity}